import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image, ImageDraw
from skimage.filters import threshold_local, threshold_yen, threshold_otsu
from pdf2image import convert_from_bytes, convert_from_path
import pytesseract

# loads image from streamlit upload element or sample image
@st.cache
def read_image(file_object, dpi = 300, sample_image = False):
    if not sample_image:
        img = convert_from_bytes(file_object.getvalue(), dpi = dpi, fmt = 'tiff')[0]
    else:
        img = convert_from_path('sample_doc.pdf', dpi = dpi, fmt = 'tiff')[0]
    return img

# runs tessearct ocr and draws bounding boxes
@st.cache
def run_ocr(input_img, draw_bboxes = False, oem = 1, psm = 12):
    img = input_img.copy()
    tess_config = '--oem {} --psm {} -c tessedit_write_images=1'.format(oem, psm)
    try:
        ocr_data = pytesseract.image_to_data(img, lang = 'deu', config = tess_config, output_type = pytesseract.Output.DICT)
        ocr_data = pd.DataFrame(ocr_data)
        ocr_data = ocr_data[ocr_data.height < 400]
        ocr_data = ocr_data[ocr_data.width < 400]
        ocr_data = ocr_data.reset_index(drop = True)
        if draw_bboxes:
            draw = ImageDraw.Draw(img)
            for i in range(0, len(ocr_data['text'])):
                x = ocr_data['left'][i]
                y = ocr_data['top'][i]
                w = ocr_data['width'][i]
                h = ocr_data['height'][i]
                draw.rectangle([x, y, (x + w), (y + h)], outline = 'red', width = 2)
        return (img, 0)
    # for some oem & psm combinations, tessearct does not write the tsv file with the bounding boxes
    except FileNotFoundError as e:
        print('No bounding boxes generated by Tessearct.')
        return (img, 1)

# define selection options for ocr engine mode
oem_dict = {
    'Neural nets LSTM engine only.': 1,
    'Legacy engine only.': 0,
    'Legacy + LSTM engines.': 2,
    'Default, based on what is available.': 3
}

# define selection options for page segmentation mode
psm_dict = {
    # 'Orientation and script detection (OSD) only': 0,
    'Fully automatic page segmentation, but no OSD. (Default)': 3,
    'Sparse text. Find as much text as possible.': 11,
    'Sparse text with OSD.': 12,
    'Automatic page segmentation with OSD': 1,
    'Automatic page segmentation, but no OSD, or OCR': 2,
    'Assume a single column of text of variable sizes.': 4,
    'Assume a single uniform block of vertically aligned text.': 5,
    'Assume a single uniform block of text.': 6,
    'Treat the image as a single text line.': 7,
    'Treat the image as a single word.': 8,
    'Treat the image as a single word in a circle.': 9,
    'Treat the image as a single character.': 10,
    'Raw line. Treat the image as a single text line.': 13
}

# define selection options for binarization
bin_list = ['none', 'local', 'yen', 'otsu']

# set up streamlit page
st.set_page_config('Vizeract', layout = 'wide')
st.title('Tesseract OCR visualization')

# set up sidebar width
st.markdown(
    """
    <style>
    [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
        width: 500px;
    }
    [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
        width: 500px;
        margin-left: -500px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# define sidebar
with st.sidebar:
    uploaded_pdf = st.file_uploader('Select PDF', type = ['pdf '])
    use_example = st.checkbox('Use example PDF')
    selected_psm = st.selectbox('Select page segmentation mode', list(psm_dict.keys()))
    selected_oem = st.selectbox('Select OCR engine mode', list(oem_dict.keys()))
    selected_bin = st.selectbox('Select binarization', bin_list)
    if selected_bin == 'local':
        block_size = st.sidebar.slider('Select block size', 1, 399, 301, 10)
    submitted = st.button(label='Run OCR')


# show image output
if use_example or uploaded_pdf is not None:

    img = read_image(uploaded_pdf, sample_image = use_example)

    if selected_bin == 'local':
        img = np.array(img.convert(mode = 'L'))
        thresh = threshold_local(img, block_size = block_size)
        binary = img > thresh
        img = Image.fromarray(binary)
        img = img.convert(mode = 'RGB')
    elif selected_bin == 'yen':
        img = np.array(img.convert(mode = 'L'))
        thresh = threshold_yen(img)
        binary = img > thresh
        img = Image.fromarray(binary)
        img = img.convert(mode = 'RGB')
    elif selected_bin == 'otsu':
        img = np.array(img.convert(mode = 'L'))
        thresh = threshold_otsu(img)
        binary = img > thresh
        img = Image.fromarray(binary)
        img = img.convert(mode = 'RGB')

    # run ocr
    if submitted:
        try:
            img, failed = run_ocr(img, draw_bboxes = True, oem = oem_dict[selected_oem], psm = psm_dict[selected_psm])
            if failed:
                st.write('No bounding boxes generated by Tessearct.')
            else:
                st.image(
                    caption = 'OCR output',
                    image = img,
                    use_column_width = 'always'
                )
        except:
            st.write('OEM - PEM combination not available or error in image processing.')

    if not submitted:
        st.image(
            caption = 'OCR output',
            image = img,
            use_column_width = 'always'
        )
